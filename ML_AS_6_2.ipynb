{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4kYHX6ykaIi13uJ0QSCkd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saivenkat2309/ML_A1/blob/main/ML_AS_6_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXbwLYYq-WKc",
        "outputId": "476db178-baa5-4eec-88d1-d82aaf41f121"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.41)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.12)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "time: 453 µs (started: 2023-12-02 00:43:03 +00:00)\n"
          ]
        }
      ],
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8UV12WE-qfD",
        "outputId": "e79c59ae-0d32-49ec-e88a-7d333f17e4ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.6 s (started: 2023-12-02 00:43:14 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LKASAL2-lLd",
        "outputId": "3a9b941d-57f7-4b09-a68b-b8d1923d3ddc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c1de2761af0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.2 ms (started: 2023-12-02 00:43:34 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Calculate mean and std\n",
        "imgs = torch.stack([img_t for img_t, _ in train_dataset], dim=3)\n",
        "mean = imgs.view(3, -1).mean(dim=1)\n",
        "std = imgs.view(3, -1).std(dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIjxRdoS-xWY",
        "outputId": "e124f109-e48d-4708-e93e-0cd1a265b65a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:11<00:00, 14706947.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "time: 33.3 s (started: 2023-12-02 00:43:48 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilMbpL_W-7eb",
        "outputId": "38edfccc-243c-4fc3-870b-ebf6c2668aff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4914, 0.4822, 0.4465])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 36.1 ms (started: 2023-12-02 00:44:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZLu_1EJ-0r4",
        "outputId": "49ddb3c7-6c4b-47a4-b44c-e8602537edf0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2470, 0.2435, 0.2616])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 6.47 ms (started: 2023-12-02 00:44:30 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPbNdiqc--zY",
        "outputId": "a08409c3-9667-4bd4-855c-68aeee437e8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.77 ms (started: 2023-12-02 00:44:41 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xduEJmI__By3",
        "outputId": "63f39f53-42c4-4228-c51b-e2b3fdbf6802"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.18 ms (started: 2023-12-02 00:44:59 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s79rcUlt_F_C",
        "outputId": "ead9030d-b21e-44f6-a659-80f79cacb9b1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 852 µs (started: 2023-12-02 00:45:01 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10 = datasets.CIFAR10(\n",
        "    './data', train=True, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObkYCqd0_Gm8",
        "outputId": "5153c5e4-d72a-4576-ab20-6c25e0b31554"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 649 ms (started: 2023-12-02 00:45:12 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "     './data', train=False, download=False,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8JIUoqA_JPD",
        "outputId": "e9996f41-8d44-46a8-b66c-bb5789dbe4ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 504 ms (started: 2023-12-02 00:45:33 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_image, label = cifar10[0]\n",
        "print(first_image.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgeN9FRQ_OXx",
        "outputId": "aeb2c444-1b24-427a-b6ec-c5fca87c74d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 32, 32])\n",
            "time: 10.9 ms (started: 2023-12-02 00:45:44 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(cifar10, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(cifar10_val, batch_size=32, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25b03A5A_RAQ",
        "outputId": "03ba4227-19ea-4a43-e56f-aefa56561875"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1e+03 µs (started: 2023-12-02 00:45:56 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 32 * 3, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, 10)\n",
        ").to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C081PE6K_T-b",
        "outputId": "38df6b8d-a124-41aa-81d4-50e99be59e65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 18.8 ms (started: 2023-12-02 00:46:07 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_loader, num_epochs=300, lr=0.001):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Testing the model\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_predicted = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_predicted.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = correct / total\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}, Test Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "    # Classification Report\n",
        "    report = classification_report(all_labels, all_predicted)\n",
        "    print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWO2lvXd_WkV",
        "outputId": "c6752397-6b6a-423f-9740-6f795da5b445"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.22 ms (started: 2023-12-02 00:47:06 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, test_loader, num_epochs=300, lr=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxMudtwp_k86",
        "outputId": "f4b95de3-2a9c-4c6f-af30-06cc9156f578"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300, Loss: 1.7886348081870638, Test Accuracy: 40.94%\n",
            "Epoch 2/300, Loss: 1.6521172705020037, Test Accuracy: 43.15%\n",
            "Epoch 3/300, Loss: 1.5804378465437692, Test Accuracy: 44.45%\n",
            "Epoch 4/300, Loss: 1.5198366514246813, Test Accuracy: 45.26%\n",
            "Epoch 5/300, Loss: 1.4625313013544161, Test Accuracy: 46.44%\n",
            "Epoch 6/300, Loss: 1.4085316710646, Test Accuracy: 47.50%\n",
            "Epoch 7/300, Loss: 1.3539841107580803, Test Accuracy: 47.11%\n",
            "Epoch 8/300, Loss: 1.3031534532744078, Test Accuracy: 47.23%\n",
            "Epoch 9/300, Loss: 1.249340126015632, Test Accuracy: 48.36%\n",
            "Epoch 10/300, Loss: 1.1990976107097633, Test Accuracy: 47.90%\n",
            "Epoch 11/300, Loss: 1.147438968516891, Test Accuracy: 48.39%\n",
            "Epoch 12/300, Loss: 1.0958708692496966, Test Accuracy: 49.10%\n",
            "Epoch 13/300, Loss: 1.0460041413990564, Test Accuracy: 48.73%\n",
            "Epoch 14/300, Loss: 0.9943198018247931, Test Accuracy: 48.12%\n",
            "Epoch 15/300, Loss: 0.9466876947223873, Test Accuracy: 48.06%\n",
            "Epoch 16/300, Loss: 0.8974496146195681, Test Accuracy: 48.03%\n",
            "Epoch 17/300, Loss: 0.8493160491216968, Test Accuracy: 48.20%\n",
            "Epoch 18/300, Loss: 0.8030849673087522, Test Accuracy: 47.89%\n",
            "Epoch 19/300, Loss: 0.7584418158308482, Test Accuracy: 47.59%\n",
            "Epoch 20/300, Loss: 0.7151811761079655, Test Accuracy: 47.85%\n",
            "Epoch 21/300, Loss: 0.6756449853161246, Test Accuracy: 46.26%\n",
            "Epoch 22/300, Loss: 0.6319736301021857, Test Accuracy: 48.21%\n",
            "Epoch 23/300, Loss: 0.5908622399439662, Test Accuracy: 47.18%\n",
            "Epoch 24/300, Loss: 0.5566875617700895, Test Accuracy: 47.14%\n",
            "Epoch 25/300, Loss: 0.518112089501614, Test Accuracy: 46.81%\n",
            "Epoch 26/300, Loss: 0.48450431075144945, Test Accuracy: 46.79%\n",
            "Epoch 27/300, Loss: 0.4544286360381432, Test Accuracy: 46.92%\n",
            "Epoch 28/300, Loss: 0.4219303291364885, Test Accuracy: 47.37%\n",
            "Epoch 29/300, Loss: 0.3913330497912543, Test Accuracy: 46.04%\n",
            "Epoch 30/300, Loss: 0.36696073348066094, Test Accuracy: 47.30%\n",
            "Epoch 31/300, Loss: 0.3374213149731768, Test Accuracy: 46.83%\n",
            "Epoch 32/300, Loss: 0.31385827586483817, Test Accuracy: 46.64%\n",
            "Epoch 33/300, Loss: 0.29224866034697816, Test Accuracy: 46.86%\n",
            "Epoch 34/300, Loss: 0.2670081588925266, Test Accuracy: 46.87%\n",
            "Epoch 35/300, Loss: 0.24813721908622266, Test Accuracy: 46.66%\n",
            "Epoch 36/300, Loss: 0.23375389504264885, Test Accuracy: 45.88%\n",
            "Epoch 37/300, Loss: 0.2140110737321778, Test Accuracy: 44.58%\n",
            "Epoch 38/300, Loss: 0.1977330784617863, Test Accuracy: 46.29%\n",
            "Epoch 39/300, Loss: 0.18204637396644494, Test Accuracy: 45.95%\n",
            "Epoch 40/300, Loss: 0.16695387970587036, Test Accuracy: 46.55%\n",
            "Epoch 41/300, Loss: 0.15741203715089264, Test Accuracy: 45.88%\n",
            "Epoch 42/300, Loss: 0.14299652590079714, Test Accuracy: 46.73%\n",
            "Epoch 43/300, Loss: 0.13252591986926565, Test Accuracy: 47.06%\n",
            "Epoch 44/300, Loss: 0.12256554260692647, Test Accuracy: 46.26%\n",
            "Epoch 45/300, Loss: 0.11413938269109697, Test Accuracy: 46.65%\n",
            "Epoch 46/300, Loss: 0.10578923942479504, Test Accuracy: 46.28%\n",
            "Epoch 47/300, Loss: 0.09701926458772374, Test Accuracy: 46.52%\n",
            "Epoch 48/300, Loss: 0.09125530832016308, Test Accuracy: 46.09%\n",
            "Epoch 49/300, Loss: 0.08323960484351703, Test Accuracy: 45.85%\n",
            "Epoch 50/300, Loss: 0.07793031386096777, Test Accuracy: 46.47%\n",
            "Epoch 51/300, Loss: 0.07340179563703174, Test Accuracy: 46.87%\n",
            "Epoch 52/300, Loss: 0.06789153587890602, Test Accuracy: 46.78%\n",
            "Epoch 53/300, Loss: 0.06405183663013762, Test Accuracy: 46.37%\n",
            "Epoch 54/300, Loss: 0.0600957814508707, Test Accuracy: 46.46%\n",
            "Epoch 55/300, Loss: 0.05622955678139294, Test Accuracy: 46.63%\n",
            "Epoch 56/300, Loss: 0.05343070523771657, Test Accuracy: 46.30%\n",
            "Epoch 57/300, Loss: 0.050525530729435685, Test Accuracy: 46.39%\n",
            "Epoch 58/300, Loss: 0.04866047613251232, Test Accuracy: 46.61%\n",
            "Epoch 59/300, Loss: 0.04477761479205454, Test Accuracy: 46.35%\n",
            "Epoch 60/300, Loss: 0.04320085038545989, Test Accuracy: 46.14%\n",
            "Epoch 61/300, Loss: 0.04076752209498458, Test Accuracy: 46.08%\n",
            "Epoch 62/300, Loss: 0.03865865762783447, Test Accuracy: 46.75%\n",
            "Epoch 63/300, Loss: 0.03657484882626199, Test Accuracy: 46.46%\n",
            "Epoch 64/300, Loss: 0.03542648075280743, Test Accuracy: 46.50%\n",
            "Epoch 65/300, Loss: 0.033578440731108876, Test Accuracy: 46.75%\n",
            "Epoch 66/300, Loss: 0.03269095509417322, Test Accuracy: 46.60%\n",
            "Epoch 67/300, Loss: 0.030699097605628306, Test Accuracy: 46.80%\n",
            "Epoch 68/300, Loss: 0.02998452520347126, Test Accuracy: 46.49%\n",
            "Epoch 69/300, Loss: 0.028528229944808355, Test Accuracy: 46.47%\n",
            "Epoch 70/300, Loss: 0.02694758165255904, Test Accuracy: 46.21%\n",
            "Epoch 71/300, Loss: 0.02668847565218015, Test Accuracy: 46.48%\n",
            "Epoch 72/300, Loss: 0.025075945568819764, Test Accuracy: 46.66%\n",
            "Epoch 73/300, Loss: 0.02466983015107388, Test Accuracy: 46.84%\n",
            "Epoch 74/300, Loss: 0.02402608683398345, Test Accuracy: 46.53%\n",
            "Epoch 75/300, Loss: 0.023083230435862537, Test Accuracy: 46.30%\n",
            "Epoch 76/300, Loss: 0.022875311340533687, Test Accuracy: 45.97%\n",
            "Epoch 77/300, Loss: 0.021731449574141533, Test Accuracy: 46.55%\n",
            "Epoch 78/300, Loss: 0.021448273174178693, Test Accuracy: 46.52%\n",
            "Epoch 79/300, Loss: 0.020670220698572585, Test Accuracy: 46.26%\n",
            "Epoch 80/300, Loss: 0.0195862539636921, Test Accuracy: 46.81%\n",
            "Epoch 81/300, Loss: 0.019641837506165927, Test Accuracy: 46.74%\n",
            "Epoch 82/300, Loss: 0.01876176614671831, Test Accuracy: 46.37%\n",
            "Epoch 83/300, Loss: 0.01837130212919192, Test Accuracy: 46.63%\n",
            "Epoch 84/300, Loss: 0.01816597857267637, Test Accuracy: 46.64%\n",
            "Epoch 85/300, Loss: 0.017544476555211092, Test Accuracy: 46.46%\n",
            "Epoch 86/300, Loss: 0.016873627706232432, Test Accuracy: 46.45%\n",
            "Epoch 87/300, Loss: 0.017143391363825637, Test Accuracy: 46.52%\n",
            "Epoch 88/300, Loss: 0.016380528962896258, Test Accuracy: 46.51%\n",
            "Epoch 89/300, Loss: 0.015886996532489456, Test Accuracy: 46.32%\n",
            "Epoch 90/300, Loss: 0.015363656431591462, Test Accuracy: 46.62%\n",
            "Epoch 91/300, Loss: 0.014941332523632968, Test Accuracy: 46.39%\n",
            "Epoch 92/300, Loss: 0.01471734142839022, Test Accuracy: 46.36%\n",
            "Epoch 93/300, Loss: 0.014288926734848238, Test Accuracy: 46.58%\n",
            "Epoch 94/300, Loss: 0.014111164306610422, Test Accuracy: 46.30%\n",
            "Epoch 95/300, Loss: 0.013687521494538907, Test Accuracy: 46.27%\n",
            "Epoch 96/300, Loss: 0.013534353128965093, Test Accuracy: 46.33%\n",
            "Epoch 97/300, Loss: 0.013250522929531541, Test Accuracy: 46.49%\n",
            "Epoch 98/300, Loss: 0.012950430891726235, Test Accuracy: 46.56%\n",
            "Epoch 99/300, Loss: 0.012681678208622007, Test Accuracy: 46.68%\n",
            "Epoch 100/300, Loss: 0.012520023269765913, Test Accuracy: 46.49%\n",
            "Epoch 101/300, Loss: 0.012335369779930348, Test Accuracy: 46.60%\n",
            "Epoch 102/300, Loss: 0.012068102038533963, Test Accuracy: 46.37%\n",
            "Epoch 103/300, Loss: 0.011870389203025565, Test Accuracy: 46.45%\n",
            "Epoch 104/300, Loss: 0.011635880608359496, Test Accuracy: 46.39%\n",
            "Epoch 105/300, Loss: 0.011446556186044895, Test Accuracy: 46.22%\n",
            "Epoch 106/300, Loss: 0.011449126720962353, Test Accuracy: 46.39%\n",
            "Epoch 107/300, Loss: 0.011080324867894004, Test Accuracy: 46.44%\n",
            "Epoch 108/300, Loss: 0.01091612842510754, Test Accuracy: 46.53%\n",
            "Epoch 109/300, Loss: 0.010745574411550586, Test Accuracy: 46.41%\n",
            "Epoch 110/300, Loss: 0.010496180533161547, Test Accuracy: 46.47%\n",
            "Epoch 111/300, Loss: 0.01035216191970646, Test Accuracy: 46.69%\n",
            "Epoch 112/300, Loss: 0.010294637492049298, Test Accuracy: 46.31%\n",
            "Epoch 113/300, Loss: 0.010068107112141008, Test Accuracy: 46.57%\n",
            "Epoch 114/300, Loss: 0.009943575087353176, Test Accuracy: 46.46%\n",
            "Epoch 115/300, Loss: 0.009806347389122136, Test Accuracy: 46.58%\n",
            "Epoch 116/300, Loss: 0.009609846772133866, Test Accuracy: 46.71%\n",
            "Epoch 117/300, Loss: 0.009482827100733573, Test Accuracy: 46.40%\n",
            "Epoch 118/300, Loss: 0.009367233553695148, Test Accuracy: 46.42%\n",
            "Epoch 119/300, Loss: 0.009251358316137537, Test Accuracy: 46.31%\n",
            "Epoch 120/300, Loss: 0.00911956567434035, Test Accuracy: 46.59%\n",
            "Epoch 121/300, Loss: 0.00893467967443154, Test Accuracy: 46.32%\n",
            "Epoch 122/300, Loss: 0.00887006637357266, Test Accuracy: 46.53%\n",
            "Epoch 123/300, Loss: 0.008757781855862108, Test Accuracy: 46.43%\n",
            "Epoch 124/300, Loss: 0.008623649449023923, Test Accuracy: 46.31%\n",
            "Epoch 125/300, Loss: 0.008564376571082813, Test Accuracy: 46.44%\n",
            "Epoch 126/300, Loss: 0.008428683381418025, Test Accuracy: 46.05%\n",
            "Epoch 127/300, Loss: 0.008314380125945252, Test Accuracy: 46.52%\n",
            "Epoch 128/300, Loss: 0.008205748831415912, Test Accuracy: 46.30%\n",
            "Epoch 129/300, Loss: 0.008111260352883861, Test Accuracy: 46.58%\n",
            "Epoch 130/300, Loss: 0.007993335385168696, Test Accuracy: 46.71%\n",
            "Epoch 131/300, Loss: 0.007903217812922622, Test Accuracy: 46.24%\n",
            "Epoch 132/300, Loss: 0.00781233190566001, Test Accuracy: 46.54%\n",
            "Epoch 133/300, Loss: 0.00770140274502909, Test Accuracy: 46.56%\n",
            "Epoch 134/300, Loss: 0.0076539544820647286, Test Accuracy: 46.33%\n",
            "Epoch 135/300, Loss: 0.007530021327932056, Test Accuracy: 46.41%\n",
            "Epoch 136/300, Loss: 0.007434082744399983, Test Accuracy: 46.60%\n",
            "Epoch 137/300, Loss: 0.0073594021711019435, Test Accuracy: 46.49%\n",
            "Epoch 138/300, Loss: 0.007285498056122205, Test Accuracy: 46.58%\n",
            "Epoch 139/300, Loss: 0.0071995996166096905, Test Accuracy: 46.53%\n",
            "Epoch 140/300, Loss: 0.007124542555416042, Test Accuracy: 46.42%\n",
            "Epoch 141/300, Loss: 0.00705536986166112, Test Accuracy: 46.52%\n",
            "Epoch 142/300, Loss: 0.006963541256341314, Test Accuracy: 46.42%\n",
            "Epoch 143/300, Loss: 0.0068913316613352805, Test Accuracy: 46.43%\n",
            "Epoch 144/300, Loss: 0.006836607304454727, Test Accuracy: 46.60%\n",
            "Epoch 145/300, Loss: 0.006761622746246828, Test Accuracy: 46.42%\n",
            "Epoch 146/300, Loss: 0.006673188021457775, Test Accuracy: 46.44%\n",
            "Epoch 147/300, Loss: 0.006614029655228258, Test Accuracy: 46.43%\n",
            "Epoch 148/300, Loss: 0.006542946558036935, Test Accuracy: 46.21%\n",
            "Epoch 149/300, Loss: 0.006486058564229808, Test Accuracy: 46.51%\n",
            "Epoch 150/300, Loss: 0.006419555968423246, Test Accuracy: 46.41%\n",
            "Epoch 151/300, Loss: 0.006365720535701788, Test Accuracy: 46.37%\n",
            "Epoch 152/300, Loss: 0.006286170895515881, Test Accuracy: 46.45%\n",
            "Epoch 153/300, Loss: 0.006236795647491677, Test Accuracy: 46.44%\n",
            "Epoch 154/300, Loss: 0.006177555565452364, Test Accuracy: 46.41%\n",
            "Epoch 155/300, Loss: 0.0061134056298995315, Test Accuracy: 46.60%\n",
            "Epoch 156/300, Loss: 0.006044875722115124, Test Accuracy: 46.34%\n",
            "Epoch 157/300, Loss: 0.005995429740945784, Test Accuracy: 46.16%\n",
            "Epoch 158/300, Loss: 0.005953047102643743, Test Accuracy: 46.54%\n",
            "Epoch 159/300, Loss: 0.00588813055216103, Test Accuracy: 46.36%\n",
            "Epoch 160/300, Loss: 0.005829815159034001, Test Accuracy: 46.30%\n",
            "Epoch 161/300, Loss: 0.005788469020788506, Test Accuracy: 46.33%\n",
            "Epoch 162/300, Loss: 0.0057194081509887446, Test Accuracy: 46.42%\n",
            "Epoch 163/300, Loss: 0.0056900763891634945, Test Accuracy: 46.34%\n",
            "Epoch 164/300, Loss: 0.0056314890672734584, Test Accuracy: 46.43%\n",
            "Epoch 165/300, Loss: 0.0055843182532289565, Test Accuracy: 46.34%\n",
            "Epoch 166/300, Loss: 0.005529932334532893, Test Accuracy: 46.25%\n",
            "Epoch 167/300, Loss: 0.005480694986006301, Test Accuracy: 46.41%\n",
            "Epoch 168/300, Loss: 0.005439800962416058, Test Accuracy: 46.35%\n",
            "Epoch 169/300, Loss: 0.00538251282300464, Test Accuracy: 46.50%\n",
            "Epoch 170/300, Loss: 0.005337228367828495, Test Accuracy: 46.44%\n",
            "Epoch 171/300, Loss: 0.005294682984183747, Test Accuracy: 46.41%\n",
            "Epoch 172/300, Loss: 0.005262249360315058, Test Accuracy: 46.17%\n",
            "Epoch 173/300, Loss: 0.005215800102288886, Test Accuracy: 46.34%\n",
            "Epoch 174/300, Loss: 0.005173319725764252, Test Accuracy: 46.43%\n",
            "Epoch 175/300, Loss: 0.0051209048735381835, Test Accuracy: 46.55%\n",
            "Epoch 176/300, Loss: 0.005078459693022401, Test Accuracy: 46.36%\n",
            "Epoch 177/300, Loss: 0.0050439278415499, Test Accuracy: 46.53%\n",
            "Epoch 178/300, Loss: 0.005007016551767262, Test Accuracy: 46.35%\n",
            "Epoch 179/300, Loss: 0.004973149739690864, Test Accuracy: 46.33%\n",
            "Epoch 180/300, Loss: 0.004930987740078522, Test Accuracy: 46.23%\n",
            "Epoch 181/300, Loss: 0.004888740459651289, Test Accuracy: 46.47%\n",
            "Epoch 182/300, Loss: 0.004847669434719984, Test Accuracy: 46.27%\n",
            "Epoch 183/300, Loss: 0.004811947973134021, Test Accuracy: 46.40%\n",
            "Epoch 184/300, Loss: 0.00477013222352433, Test Accuracy: 46.48%\n",
            "Epoch 185/300, Loss: 0.004737283959561722, Test Accuracy: 46.22%\n",
            "Epoch 186/300, Loss: 0.00470068693349897, Test Accuracy: 46.44%\n",
            "Epoch 187/300, Loss: 0.004673335423111506, Test Accuracy: 46.30%\n",
            "Epoch 188/300, Loss: 0.004640165088526662, Test Accuracy: 46.41%\n",
            "Epoch 189/300, Loss: 0.004602413316914527, Test Accuracy: 46.46%\n",
            "Epoch 190/300, Loss: 0.004566066762103544, Test Accuracy: 46.37%\n",
            "Epoch 191/300, Loss: 0.004537050017457806, Test Accuracy: 46.43%\n",
            "Epoch 192/300, Loss: 0.004504614870432795, Test Accuracy: 46.47%\n",
            "Epoch 193/300, Loss: 0.004479275698763433, Test Accuracy: 46.32%\n",
            "Epoch 194/300, Loss: 0.004435529055131059, Test Accuracy: 46.36%\n",
            "Epoch 195/300, Loss: 0.004408082138253608, Test Accuracy: 46.41%\n",
            "Epoch 196/300, Loss: 0.004372622498971907, Test Accuracy: 46.43%\n",
            "Epoch 197/300, Loss: 0.0043425731452078255, Test Accuracy: 46.41%\n",
            "Epoch 198/300, Loss: 0.0043176171528944126, Test Accuracy: 46.32%\n",
            "Epoch 199/300, Loss: 0.004283114826224473, Test Accuracy: 46.40%\n",
            "Epoch 200/300, Loss: 0.004257794865243189, Test Accuracy: 46.43%\n",
            "Epoch 201/300, Loss: 0.00422845135209933, Test Accuracy: 46.52%\n",
            "Epoch 202/300, Loss: 0.004198365622382999, Test Accuracy: 46.29%\n",
            "Epoch 203/300, Loss: 0.00417097257086751, Test Accuracy: 46.39%\n",
            "Epoch 204/300, Loss: 0.004140672800074536, Test Accuracy: 46.41%\n",
            "Epoch 205/300, Loss: 0.004115963240898311, Test Accuracy: 46.32%\n",
            "Epoch 206/300, Loss: 0.004081610707603085, Test Accuracy: 46.42%\n",
            "Epoch 207/300, Loss: 0.0040638568183682475, Test Accuracy: 46.41%\n",
            "Epoch 208/300, Loss: 0.004034158541038585, Test Accuracy: 46.38%\n",
            "Epoch 209/300, Loss: 0.004003579805319698, Test Accuracy: 46.52%\n",
            "Epoch 210/300, Loss: 0.003977131998474499, Test Accuracy: 46.42%\n",
            "Epoch 211/300, Loss: 0.0039572251781282595, Test Accuracy: 46.29%\n",
            "Epoch 212/300, Loss: 0.003933481389662026, Test Accuracy: 46.42%\n",
            "Epoch 213/300, Loss: 0.003908129309000768, Test Accuracy: 46.50%\n",
            "Epoch 214/300, Loss: 0.0038802997332473862, Test Accuracy: 46.43%\n",
            "Epoch 215/300, Loss: 0.0038570784199482362, Test Accuracy: 46.50%\n",
            "Epoch 216/300, Loss: 0.0038284156981692368, Test Accuracy: 46.31%\n",
            "Epoch 217/300, Loss: 0.0038081994126786217, Test Accuracy: 46.43%\n",
            "Epoch 218/300, Loss: 0.003789753064999425, Test Accuracy: 46.13%\n",
            "Epoch 219/300, Loss: 0.0037612617273546246, Test Accuracy: 46.32%\n",
            "Epoch 220/300, Loss: 0.003737788517218767, Test Accuracy: 46.47%\n",
            "Epoch 221/300, Loss: 0.003717697059267313, Test Accuracy: 46.28%\n",
            "Epoch 222/300, Loss: 0.0036967343421949648, Test Accuracy: 46.44%\n",
            "Epoch 223/300, Loss: 0.0036737007834225827, Test Accuracy: 46.27%\n",
            "Epoch 224/300, Loss: 0.003653723528231503, Test Accuracy: 46.33%\n",
            "Epoch 225/300, Loss: 0.0036288713273650093, Test Accuracy: 46.33%\n",
            "Epoch 226/300, Loss: 0.0036061756333404162, Test Accuracy: 46.33%\n",
            "Epoch 227/300, Loss: 0.003588431019047591, Test Accuracy: 46.38%\n",
            "Epoch 228/300, Loss: 0.003568144407083405, Test Accuracy: 46.42%\n",
            "Epoch 229/300, Loss: 0.003544409252641817, Test Accuracy: 46.39%\n",
            "Epoch 230/300, Loss: 0.0035226147203877216, Test Accuracy: 46.37%\n",
            "Epoch 231/300, Loss: 0.0035048010469320746, Test Accuracy: 46.34%\n",
            "Epoch 232/300, Loss: 0.003484587505953154, Test Accuracy: 46.38%\n",
            "Epoch 233/300, Loss: 0.003466156128107529, Test Accuracy: 46.38%\n",
            "Epoch 234/300, Loss: 0.0034434198739569603, Test Accuracy: 46.26%\n",
            "Epoch 235/300, Loss: 0.0034248108621204054, Test Accuracy: 46.41%\n",
            "Epoch 236/300, Loss: 0.003407718024144494, Test Accuracy: 46.39%\n",
            "Epoch 237/300, Loss: 0.003387728432504435, Test Accuracy: 46.42%\n",
            "Epoch 238/300, Loss: 0.0033648654688787256, Test Accuracy: 46.28%\n",
            "Epoch 239/300, Loss: 0.003347438299132872, Test Accuracy: 46.45%\n",
            "Epoch 240/300, Loss: 0.003331032436462006, Test Accuracy: 46.39%\n",
            "Epoch 241/300, Loss: 0.0033131123425692833, Test Accuracy: 46.34%\n",
            "Epoch 242/300, Loss: 0.0032924102924368507, Test Accuracy: 46.36%\n",
            "Epoch 243/300, Loss: 0.0032770960729227175, Test Accuracy: 46.48%\n",
            "Epoch 244/300, Loss: 0.0032582972279165275, Test Accuracy: 46.37%\n",
            "Epoch 245/300, Loss: 0.0032412573656154246, Test Accuracy: 46.44%\n",
            "Epoch 246/300, Loss: 0.003223197243902749, Test Accuracy: 46.34%\n",
            "Epoch 247/300, Loss: 0.0032095514058826046, Test Accuracy: 46.42%\n",
            "Epoch 248/300, Loss: 0.0031895194375012796, Test Accuracy: 46.45%\n",
            "Epoch 249/300, Loss: 0.0031713938045745058, Test Accuracy: 46.33%\n",
            "Epoch 250/300, Loss: 0.003157238603268064, Test Accuracy: 46.50%\n",
            "Epoch 251/300, Loss: 0.0031408669130003138, Test Accuracy: 46.39%\n",
            "Epoch 252/300, Loss: 0.0031252729053855162, Test Accuracy: 46.31%\n",
            "Epoch 253/300, Loss: 0.0031075899632825197, Test Accuracy: 46.28%\n",
            "Epoch 254/300, Loss: 0.0030900551731205443, Test Accuracy: 46.47%\n",
            "Epoch 255/300, Loss: 0.003080192890187448, Test Accuracy: 46.45%\n",
            "Epoch 256/300, Loss: 0.003061778238683734, Test Accuracy: 46.32%\n",
            "Epoch 257/300, Loss: 0.003046404727125661, Test Accuracy: 46.48%\n",
            "Epoch 258/300, Loss: 0.0030268456146177037, Test Accuracy: 46.38%\n",
            "Epoch 259/300, Loss: 0.003014522163413098, Test Accuracy: 46.40%\n",
            "Epoch 260/300, Loss: 0.002998722334775504, Test Accuracy: 46.38%\n",
            "Epoch 261/300, Loss: 0.002982027942352879, Test Accuracy: 46.32%\n",
            "Epoch 262/300, Loss: 0.002969718253331155, Test Accuracy: 46.48%\n",
            "Epoch 263/300, Loss: 0.002952626858071036, Test Accuracy: 46.37%\n",
            "Epoch 264/300, Loss: 0.0029414609968078324, Test Accuracy: 46.42%\n",
            "Epoch 265/300, Loss: 0.0029243383523385427, Test Accuracy: 46.38%\n",
            "Epoch 266/300, Loss: 0.0029117256463746647, Test Accuracy: 46.34%\n",
            "Epoch 267/300, Loss: 0.002897987902368242, Test Accuracy: 46.43%\n",
            "Epoch 268/300, Loss: 0.0028830282789341012, Test Accuracy: 46.35%\n",
            "Epoch 269/300, Loss: 0.002870039763977788, Test Accuracy: 46.48%\n",
            "Epoch 270/300, Loss: 0.002855990785135341, Test Accuracy: 46.41%\n",
            "Epoch 271/300, Loss: 0.00284292120333065, Test Accuracy: 46.34%\n",
            "Epoch 272/300, Loss: 0.0028310952332289085, Test Accuracy: 46.38%\n",
            "Epoch 273/300, Loss: 0.002812286183298807, Test Accuracy: 46.41%\n",
            "Epoch 274/300, Loss: 0.0028044259650406313, Test Accuracy: 46.30%\n",
            "Epoch 275/300, Loss: 0.002790762962873546, Test Accuracy: 46.29%\n",
            "Epoch 276/300, Loss: 0.0027768136607214896, Test Accuracy: 46.37%\n",
            "Epoch 277/300, Loss: 0.002761993092596197, Test Accuracy: 46.41%\n",
            "Epoch 278/300, Loss: 0.002748818992475025, Test Accuracy: 46.36%\n",
            "Epoch 279/300, Loss: 0.002736787100352933, Test Accuracy: 46.40%\n",
            "Epoch 280/300, Loss: 0.0027258174980425123, Test Accuracy: 46.38%\n",
            "Epoch 281/300, Loss: 0.002712623666827725, Test Accuracy: 46.32%\n",
            "Epoch 282/300, Loss: 0.0027022401651639254, Test Accuracy: 46.38%\n",
            "Epoch 283/300, Loss: 0.0026899651115252538, Test Accuracy: 46.32%\n",
            "Epoch 284/300, Loss: 0.00267561457789624, Test Accuracy: 46.42%\n",
            "Epoch 285/300, Loss: 0.0026632369307786827, Test Accuracy: 46.39%\n",
            "Epoch 286/300, Loss: 0.0026527357640600525, Test Accuracy: 46.35%\n",
            "Epoch 287/300, Loss: 0.002643273066701302, Test Accuracy: 46.39%\n",
            "Epoch 288/300, Loss: 0.0026288867753948863, Test Accuracy: 46.35%\n",
            "Epoch 289/300, Loss: 0.002616797818463255, Test Accuracy: 46.39%\n",
            "Epoch 290/300, Loss: 0.0026049305008866144, Test Accuracy: 46.33%\n",
            "Epoch 291/300, Loss: 0.0025932669720921714, Test Accuracy: 46.31%\n",
            "Epoch 292/300, Loss: 0.00258026281845418, Test Accuracy: 46.22%\n",
            "Epoch 293/300, Loss: 0.002571773420517605, Test Accuracy: 46.23%\n",
            "Epoch 294/300, Loss: 0.002561234738868414, Test Accuracy: 46.31%\n",
            "Epoch 295/300, Loss: 0.0025501772036635325, Test Accuracy: 46.37%\n",
            "Epoch 296/300, Loss: 0.0025344548759754374, Test Accuracy: 46.24%\n",
            "Epoch 297/300, Loss: 0.002527197924372874, Test Accuracy: 46.33%\n",
            "Epoch 298/300, Loss: 0.0025166352315235617, Test Accuracy: 46.30%\n",
            "Epoch 299/300, Loss: 0.002505141013583153, Test Accuracy: 46.33%\n",
            "Epoch 300/300, Loss: 0.002496123177825246, Test Accuracy: 46.37%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.53      0.53      1000\n",
            "           1       0.60      0.53      0.56      1000\n",
            "           2       0.34      0.38      0.36      1000\n",
            "           3       0.30      0.29      0.29      1000\n",
            "           4       0.40      0.42      0.41      1000\n",
            "           5       0.34      0.34      0.34      1000\n",
            "           6       0.48      0.52      0.50      1000\n",
            "           7       0.54      0.50      0.52      1000\n",
            "           8       0.58      0.64      0.61      1000\n",
            "           9       0.55      0.50      0.52      1000\n",
            "\n",
            "    accuracy                           0.46     10000\n",
            "   macro avg       0.47      0.46      0.46     10000\n",
            "weighted avg       0.47      0.46      0.46     10000\n",
            "\n",
            "time: 2h 45min 40s (started: 2023-12-02 00:47:18 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = nn.Sequential(\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 32 * 3, 512),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.Tanh(),\n",
        "    nn.Linear(128, 10)\n",
        ").to(device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtjUvieC_n7w",
        "outputId": "05ee2f83-198d-45ab-e648-5f347d875d7e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 23.8 ms (started: 2023-12-02 03:54:42 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model2, train_loader, test_loader, num_epochs=300, lr=0.02)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q7TEaikqhA6",
        "outputId": "b9f157a6-70d2-4643-ed1b-01a3683ef47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Loss: 1.8525115716785325, Test Accuracy: 39.86%\n",
            "Epoch 2/200, Loss: 1.6869112958682324, Test Accuracy: 41.70%\n",
            "Epoch 3/200, Loss: 1.6147569851927168, Test Accuracy: 43.42%\n",
            "Epoch 4/200, Loss: 1.5524838497374809, Test Accuracy: 45.18%\n",
            "Epoch 5/200, Loss: 1.4961205005111866, Test Accuracy: 45.93%\n",
            "Epoch 6/200, Loss: 1.4420395591132396, Test Accuracy: 46.48%\n",
            "Epoch 7/200, Loss: 1.3869562117395993, Test Accuracy: 47.04%\n",
            "Epoch 8/200, Loss: 1.3304111210871261, Test Accuracy: 47.79%\n",
            "Epoch 9/200, Loss: 1.2721629204539557, Test Accuracy: 47.46%\n",
            "Epoch 10/200, Loss: 1.2145694345903184, Test Accuracy: 48.17%\n",
            "Epoch 11/200, Loss: 1.1551353657238008, Test Accuracy: 46.41%\n",
            "Epoch 12/200, Loss: 1.0963393020767167, Test Accuracy: 46.19%\n",
            "Epoch 13/200, Loss: 1.0335245162382083, Test Accuracy: 47.70%\n",
            "Epoch 14/200, Loss: 0.9775107119301536, Test Accuracy: 48.41%\n",
            "Epoch 15/200, Loss: 0.915340742657601, Test Accuracy: 47.51%\n",
            "Epoch 16/200, Loss: 0.8570451142310486, Test Accuracy: 47.54%\n",
            "Epoch 17/200, Loss: 0.7985563852889219, Test Accuracy: 45.89%\n",
            "Epoch 18/200, Loss: 0.7450304798071612, Test Accuracy: 47.09%\n",
            "Epoch 19/200, Loss: 0.6881845293617829, Test Accuracy: 45.56%\n",
            "Epoch 20/200, Loss: 0.6381393269476644, Test Accuracy: 45.76%\n",
            "Epoch 21/200, Loss: 0.5839490179098804, Test Accuracy: 46.07%\n",
            "Epoch 22/200, Loss: 0.5411572370747306, Test Accuracy: 46.59%\n",
            "Epoch 23/200, Loss: 0.4943184415670976, Test Accuracy: 45.31%\n",
            "Epoch 24/200, Loss: 0.45511514334078407, Test Accuracy: 45.36%\n",
            "Epoch 25/200, Loss: 0.41505261018195366, Test Accuracy: 45.17%\n",
            "Epoch 26/200, Loss: 0.3722224737388235, Test Accuracy: 44.60%\n",
            "Epoch 27/200, Loss: 0.3443553796751867, Test Accuracy: 45.99%\n",
            "Epoch 28/200, Loss: 0.3152252361798088, Test Accuracy: 47.04%\n",
            "Epoch 29/200, Loss: 0.27190214890083364, Test Accuracy: 45.85%\n",
            "Epoch 30/200, Loss: 0.25638475268840866, Test Accuracy: 45.61%\n",
            "Epoch 31/200, Loss: 0.2281500390294036, Test Accuracy: 45.58%\n",
            "Epoch 32/200, Loss: 0.20301692773869842, Test Accuracy: 44.71%\n",
            "Epoch 33/200, Loss: 0.18560144259348293, Test Accuracy: 46.11%\n",
            "Epoch 34/200, Loss: 0.16419674857249644, Test Accuracy: 45.92%\n",
            "Epoch 35/200, Loss: 0.14938061500012265, Test Accuracy: 44.80%\n",
            "Epoch 36/200, Loss: 0.13218093977350878, Test Accuracy: 44.98%\n",
            "Epoch 37/200, Loss: 0.11386922468751269, Test Accuracy: 44.73%\n",
            "Epoch 38/200, Loss: 0.09047291453472521, Test Accuracy: 46.15%\n",
            "Epoch 39/200, Loss: 0.08467450053702208, Test Accuracy: 46.42%\n",
            "Epoch 40/200, Loss: 0.08527827671546101, Test Accuracy: 44.40%\n",
            "Epoch 41/200, Loss: 0.07020314324615012, Test Accuracy: 46.01%\n",
            "Epoch 42/200, Loss: 0.05826755280839428, Test Accuracy: 46.32%\n",
            "Epoch 43/200, Loss: 0.04905093771924508, Test Accuracy: 45.47%\n",
            "Epoch 44/200, Loss: 0.038255282179872556, Test Accuracy: 46.12%\n",
            "Epoch 45/200, Loss: 0.02695379892700207, Test Accuracy: 46.57%\n",
            "Epoch 46/200, Loss: 0.02313665546055571, Test Accuracy: 46.58%\n",
            "Epoch 47/200, Loss: 0.015858414263008085, Test Accuracy: 45.09%\n",
            "Epoch 48/200, Loss: 0.015585441024341189, Test Accuracy: 43.24%\n",
            "Epoch 49/200, Loss: 0.013581753495701673, Test Accuracy: 46.63%\n",
            "Epoch 50/200, Loss: 0.006618621221356814, Test Accuracy: 46.63%\n",
            "Epoch 51/200, Loss: 0.004908599837290473, Test Accuracy: 47.10%\n",
            "Epoch 52/200, Loss: 0.0033659767306985374, Test Accuracy: 47.02%\n",
            "Epoch 53/200, Loss: 0.0039252855436476, Test Accuracy: 46.97%\n",
            "Epoch 54/200, Loss: 0.0031696234000962937, Test Accuracy: 46.93%\n",
            "Epoch 55/200, Loss: 0.0029021302643363134, Test Accuracy: 47.10%\n",
            "Epoch 56/200, Loss: 0.003253128204997617, Test Accuracy: 46.91%\n",
            "Epoch 57/200, Loss: 0.0022436428302839415, Test Accuracy: 46.85%\n",
            "Epoch 58/200, Loss: 0.00202717243065737, Test Accuracy: 46.99%\n",
            "Epoch 59/200, Loss: 0.0019205494820910744, Test Accuracy: 46.95%\n",
            "Epoch 60/200, Loss: 0.0018329524379390426, Test Accuracy: 46.85%\n",
            "Epoch 61/200, Loss: 0.001744436476408234, Test Accuracy: 46.87%\n",
            "Epoch 62/200, Loss: 0.0016640693110399549, Test Accuracy: 46.85%\n",
            "Epoch 63/200, Loss: 0.0015997736693850898, Test Accuracy: 46.91%\n",
            "Epoch 64/200, Loss: 0.0015338150046927282, Test Accuracy: 46.86%\n",
            "Epoch 65/200, Loss: 0.0014805548918738565, Test Accuracy: 46.94%\n",
            "Epoch 66/200, Loss: 0.0014266631432404647, Test Accuracy: 46.97%\n",
            "Epoch 67/200, Loss: 0.0013875063597457037, Test Accuracy: 47.02%\n",
            "Epoch 68/200, Loss: 0.0013395090901304181, Test Accuracy: 46.88%\n",
            "Epoch 69/200, Loss: 0.0012933400626092021, Test Accuracy: 46.92%\n",
            "Epoch 70/200, Loss: 0.001259477940420498, Test Accuracy: 46.97%\n",
            "Epoch 71/200, Loss: 0.0012204329854801597, Test Accuracy: 47.05%\n",
            "Epoch 72/200, Loss: 0.001185681670997262, Test Accuracy: 46.98%\n",
            "Epoch 73/200, Loss: 0.0011589358029051393, Test Accuracy: 46.85%\n",
            "Epoch 74/200, Loss: 0.0011244749555618086, Test Accuracy: 46.92%\n",
            "Epoch 75/200, Loss: 0.0010943083264139527, Test Accuracy: 46.90%\n",
            "Epoch 76/200, Loss: 0.0010665880466789908, Test Accuracy: 46.84%\n",
            "Epoch 77/200, Loss: 0.0010417619956134725, Test Accuracy: 46.89%\n",
            "Epoch 78/200, Loss: 0.0010191784519240409, Test Accuracy: 46.97%\n",
            "Epoch 79/200, Loss: 0.0009937834306929906, Test Accuracy: 46.81%\n",
            "Epoch 80/200, Loss: 0.0009744798214574329, Test Accuracy: 46.88%\n",
            "Epoch 81/200, Loss: 0.0009515760119370425, Test Accuracy: 46.86%\n",
            "Epoch 82/200, Loss: 0.0009299676020490274, Test Accuracy: 46.87%\n",
            "Epoch 83/200, Loss: 0.0009122211073471027, Test Accuracy: 46.88%\n",
            "Epoch 84/200, Loss: 0.0008923661958238394, Test Accuracy: 46.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model2.parameters() if p.requires_grad)\n",
        "print(\"Total number of trainable parameters \", total_params,  '\\n')"
      ],
      "metadata": {
        "id": "MpCbeXm8qrB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hancwho8qzTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}